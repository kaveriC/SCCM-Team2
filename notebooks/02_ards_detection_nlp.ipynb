{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARDS Detection using NLP on Radiology Reports\n",
    "\n",
    "## Objective\n",
    "Implement bilateral opacity detection using ARDSFlag methodology for MIMIC-IV radiology reports.\n",
    "\n",
    "## Research Question\n",
    "How does obesity modify the relationship between early plateau pressures and clinical outcomes in ARDS patients, when ARDS onset is accurately detected using unstructured radiology reports?\n",
    "\n",
    "## Methodology\n",
    "- **Berlin Definition ARDS criteria implementation**\n",
    "- **ARDSFlag NLP patterns for bilateral opacity detection**\n",
    "- **Rule-based approach with confidence scoring**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Data paths\n",
    "DATA_BASE = '/Users/kavenchhikara/Desktop/CLIF/MIMIC-IV-3.1/physionet.org/files'\n",
    "RAD_PATH = f'{DATA_BASE}/mimic-iv-note/2.2/note/radiology.csv.gz'\n",
    "MIMIC_BASE = f'{DATA_BASE}/mimiciv/3.1'\n",
    "\n",
    "print(\"Environment setup complete!\")\n",
    "print(f\"Radiology data path: {RAD_PATH}\")\n",
    "print(f\"MIMIC base path: {MIMIC_BASE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load radiology data structure\n",
    "print(\"=== RADIOLOGY DATA STRUCTURE ===\")\n",
    "rad_sample = pd.read_csv(RAD_PATH, nrows=5)\n",
    "print(\"Columns:\", rad_sample.columns.tolist())\n",
    "print(\"Sample shape:\", rad_sample.shape)\n",
    "print(\"\\nSample data:\")\n",
    "rad_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load larger sample and identify chest imaging\n",
    "print(\"=== CHEST IMAGING IDENTIFICATION ===\")\n",
    "rad_chunk = pd.read_csv(RAD_PATH)\n",
    "\n",
    "# Filter for chest imaging\n",
    "chest_mask = rad_chunk['text'].str.contains(\n",
    "    'chest.*x.*ray|chest.*pa.*lat|chest.*film|portable.*chest|thorax', \n",
    "    case=False, na=False\n",
    ")\n",
    "chest_reports = rad_chunk[chest_mask].copy()\n",
    "\n",
    "print(f\"Total radiology reports (sample): {len(rad_chunk):,}\")\n",
    "print(f\"Chest imaging reports: {len(chest_reports):,}\")\n",
    "print(f\"Chest imaging percentage: {len(chest_reports)/len(rad_chunk):.1%}\")\n",
    "\n",
    "# Show distribution of report types\n",
    "print(\"\\nNote types in sample:\")\n",
    "print(rad_chunk['note_type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine sample chest X-ray reports\n",
    "print(\"=== SAMPLE CHEST X-RAY REPORTS ===\")\n",
    "\n",
    "for i, (idx, row) in enumerate(chest_reports.head(3).iterrows()):\n",
    "    print(f\"\\n--- Report {i+1} (ID: {row['note_id']}) ---\")\n",
    "    text = row['text'][:600] + '...' if len(row['text']) > 600 else row['text']\n",
    "    print(text)\n",
    "    print(f\"Full text length: {len(row['text'])} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ARDSFlag NLP Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BerlinARDSDetector:\n",
    "    \"\"\"\n",
    "    Berlin Definition ARDS Detection using ARDSFlag methodology\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Enhanced bilateral opacity patterns from ARDSFlag\n",
    "        self.bilateral_patterns = [\n",
    "            # Direct bilateral opacity mentions\n",
    "            r'bilateral\\s+(?:ground[窶申\s]?glass\\s+)?(?:opacit|infiltrat|consolidat|shadowing)',\n",
    "            r'(?:opacit|infiltrat|consolidat|shadowing).{0,30}bilateral',\n",
    "            \n",
    "            # Bilateral anatomical mentions\n",
    "            r'bilateral\\s+(?:lung|pulmonary|alveolar)',\n",
    "            r'both\\s+(?:lung|lower\\s+lobe|upper\\s+lobe|base)',\n",
    "            r'(?:right|left)\\s+(?:and|&|\\+)\\s+(?:left|right)\\s+(?:lung|lobe|base)',\n",
    "            \n",
    "            # Diffuse/extensive patterns\n",
    "            r'diffuse\\s+(?:bilateral\\s+)?(?:opacit|infiltrat|consolidat|ground[窶申\s]?glass)',\n",
    "            r'extensive\\s+(?:bilateral\\s+)?(?:opacit|infiltrat|consolidat)',\n",
    "            r'multifocal\\s+(?:opacit|infiltrat|consolidat)',\n",
    "            r'widespread\\s+(?:opacit|infiltrat|consolidat)',\n",
    "            \n",
    "            # Ground glass specific (common in ARDS)\n",
    "            r'bilateral\\s+ground[窶申\s]?glass',\n",
    "            r'diffuse\\s+ground[窶申\s]?glass',\n",
    "            r'ground[窶申\s]?glass\\s+(?:opacit|change).{0,20}bilateral',\n",
    "        ]\n",
    "        \n",
    "        # Exclusion patterns for negation\n",
    "        self.exclusion_patterns = [\n",
    "            r'no\\s+(?:bilateral|diffuse|extensive|multifocal)',\n",
    "            r'without\\s+(?:bilateral|diffuse|extensive)',\n",
    "            r'absence\\s+of\\s+(?:bilateral|diffuse)',\n",
    "            r'clear\\s+(?:lung|bilateral)',\n",
    "            r'resolved\\s+(?:bilateral|diffuse)',\n",
    "            r'improving\\s+(?:bilateral|diffuse)',\n",
    "        ]\n",
    "        \n",
    "        # CHF/cardiogenic patterns for exclusion\n",
    "        self.chf_patterns = [\n",
    "            r'congestive\\s+heart\\s+failure',\n",
    "            r'\\bchf\\b',\n",
    "            r'cardiogenic\\s+(?:edema|pulmonary)',\n",
    "            r'heart\\s+failure',\n",
    "            r'cardiac\\s+(?:failure|dysfunction)',\n",
    "            r'left\\s+(?:heart|ventricular)\\s+failure',\n",
    "            r'pulmonary\\s+(?:edema|congestion).{0,30}cardiac',\n",
    "        ]\n",
    "    \n",
    "    def clean_radiology_text(self, text):\n",
    "        \"\"\"Clean and normalize radiology report text\"\"\"\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        \n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Remove patient identifiers and dates\n",
    "        text = re.sub(r'___+', ' ', text)\n",
    "        text = re.sub(r'\\b\\d{1,2}[-/]\\d{1,2}[-/]\\d{2,4}\\b', ' ', text)\n",
    "        \n",
    "        # Normalize medical abbreviations\n",
    "        text = re.sub(r'\\bchf\\b', 'congestive heart failure', text)\n",
    "        text = re.sub(r'\\bcopd\\b', 'chronic obstructive pulmonary disease', text)\n",
    "        text = re.sub(r'\\bpe\\b', 'pulmonary embolism', text)\n",
    "        text = re.sub(r'\\bGGO\\b', 'ground glass opacity', text)\n",
    "        \n",
    "        # Standardize spacing around hyphens\n",
    "        text = re.sub(r'ground-glass', 'ground glass', text)\n",
    "        text = re.sub(r'ground窶身lass', 'ground glass', text)\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def detect_bilateral_opacities(self, text):\n",
    "        \"\"\"Detect bilateral opacities using enhanced pattern matching\"\"\"\n",
    "        clean_text = self.clean_radiology_text(text)\n",
    "        \n",
    "        # Check for exclusion patterns first\n",
    "        exclusions = []\n",
    "        for pattern in self.exclusion_patterns:\n",
    "            if re.search(pattern, clean_text):\n",
    "                exclusions.append(pattern)\n",
    "        \n",
    "        if exclusions:\n",
    "            return {\n",
    "                'has_bilateral_opacities': False,\n",
    "                'confidence': 0.0,\n",
    "                'matched_patterns': [],\n",
    "                'excluded_by': exclusions,\n",
    "                'reason': 'negated'\n",
    "            }\n",
    "        \n",
    "        # Check for bilateral opacity patterns\n",
    "        matched_patterns = []\n",
    "        for pattern in self.bilateral_patterns:\n",
    "            matches = re.findall(pattern, clean_text)\n",
    "            if matches:\n",
    "                matched_patterns.append({\n",
    "                    'pattern': pattern,\n",
    "                    'matches': matches\n",
    "                })\n",
    "        \n",
    "        has_bilateral = len(matched_patterns) > 0\n",
    "        \n",
    "        # Enhanced confidence scoring\n",
    "        confidence = 0.0\n",
    "        if has_bilateral:\n",
    "            base_confidence = 0.3 * len(matched_patterns)\n",
    "            \n",
    "            # Bonus for specific high-confidence patterns\n",
    "            high_conf_patterns = ['bilateral', 'diffuse', 'ground glass']\n",
    "            for pattern_info in matched_patterns:\n",
    "                for term in high_conf_patterns:\n",
    "                    if term in pattern_info['pattern']:\n",
    "                        confidence += 0.2\n",
    "            \n",
    "            confidence = min(confidence, 1.0)\n",
    "        \n",
    "        return {\n",
    "            'has_bilateral_opacities': has_bilateral,\n",
    "            'confidence': confidence,\n",
    "            'matched_patterns': matched_patterns,\n",
    "            'excluded_by': [],\n",
    "            'reason': 'detected' if has_bilateral else 'not_found'\n",
    "        }\n",
    "    \n",
    "    def detect_chf_exclusion(self, text):\n",
    "        \"\"\"Detect CHF/cardiogenic causes for exclusion\"\"\"\n",
    "        clean_text = self.clean_radiology_text(text)\n",
    "        \n",
    "        matched_chf = []\n",
    "        for pattern in self.chf_patterns:\n",
    "            matches = re.findall(pattern, clean_text)\n",
    "            if matches:\n",
    "                matched_chf.append({\n",
    "                    'pattern': pattern,\n",
    "                    'matches': matches\n",
    "                })\n",
    "        \n",
    "        has_chf = len(matched_chf) > 0\n",
    "        \n",
    "        return {\n",
    "            'has_chf': has_chf,\n",
    "            'matched_patterns': matched_chf,\n",
    "            'reason': 'chf_detected' if has_chf else 'no_chf'\n",
    "        }\n",
    "\n",
    "# Initialize detector\n",
    "detector = BerlinARDSDetector()\n",
    "print(\"ARDSFlag detector initialized!\")\n",
    "print(f\"Bilateral patterns: {len(detector.bilateral_patterns)}\")\n",
    "print(f\"Exclusion patterns: {len(detector.exclusion_patterns)}\")\n",
    "print(f\"CHF patterns: {len(detector.chf_patterns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test Pattern Detection on Sample Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on initial sample\n",
    "print(\"=== TESTING BILATERAL OPACITY DETECTION ===\")\n",
    "\n",
    "sample_reports = chest_reports.head(5)\n",
    "for idx, row in sample_reports.iterrows():\n",
    "    bilateral_result = detector.detect_bilateral_opacities(row['text'])\n",
    "    chf_result = detector.detect_chf_exclusion(row['text'])\n",
    "    \n",
    "    print(f\"\\n--- Report ID: {row['note_id']} ---\")\n",
    "    print(f\"Bilateral opacities: {bilateral_result['has_bilateral_opacities']} (confidence: {bilateral_result['confidence']:.2f})\")\n",
    "    print(f\"CHF detected: {chf_result['has_chf']}\")\n",
    "    if bilateral_result['has_bilateral_opacities']:\n",
    "        print(f\"Matched patterns: {len(bilateral_result['matched_patterns'])}\")\n",
    "    print(\"Text preview:\", row['text'][:200] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Large-Scale Analysis on Extended Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load larger dataset for comprehensive analysis\n",
    "print(\"=== LARGE-SCALE BILATERAL OPACITY ANALYSIS ===\")\n",
    "\n",
    "# Load larger sample\n",
    "rad_large = pd.read_csv(RAD_PATH, nrows=20000)\n",
    "\n",
    "# Filter for chest imaging\n",
    "chest_mask = rad_large['text'].str.contains(\n",
    "    'chest.*x.*ray|chest.*pa.*lat|chest.*film|portable.*chest|thorax', \n",
    "    case=False, na=False\n",
    ")\n",
    "chest_reports_large = rad_large[chest_mask].copy()\n",
    "\n",
    "print(f\"Large sample size: {len(rad_large):,} radiology reports\")\n",
    "print(f\"Chest imaging reports: {len(chest_reports_large):,}\")\n",
    "print(f\"Processing for bilateral opacity detection...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all chest reports for bilateral opacities\n",
    "results = []\n",
    "for idx, row in chest_reports_large.iterrows():\n",
    "    bilateral_result = detector.detect_bilateral_opacities(row['text'])\n",
    "    chf_result = detector.detect_chf_exclusion(row['text'])\n",
    "    \n",
    "    results.append({\n",
    "        'note_id': row['note_id'],\n",
    "        'subject_id': row['subject_id'],\n",
    "        'hadm_id': row['hadm_id'],\n",
    "        'charttime': row['charttime'],\n",
    "        'has_bilateral_opacities': bilateral_result['has_bilateral_opacities'],\n",
    "        'bilateral_confidence': bilateral_result['confidence'],\n",
    "        'bilateral_patterns': len(bilateral_result['matched_patterns']),\n",
    "        'has_chf': chf_result['has_chf'],\n",
    "        'chf_patterns': len(chf_result['matched_patterns']),\n",
    "        'text_length': len(row['text'])\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(f\"Processing complete! Results shape: {results_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"=== BILATERAL OPACITIES DETECTION RESULTS ===\")\n",
    "print(f\"Total reports analyzed: {len(results_df):,}\")\n",
    "print(f\"Reports with bilateral opacities: {results_df['has_bilateral_opacities'].sum():,} ({results_df['has_bilateral_opacities'].mean():.1%})\")\n",
    "print(f\"Reports with CHF mentions: {results_df['has_chf'].sum():,} ({results_df['has_chf'].mean():.1%})\")\n",
    "\n",
    "# Confidence distribution for positive cases\n",
    "positive_cases = results_df[results_df['has_bilateral_opacities']]\n",
    "if len(positive_cases) > 0:\n",
    "    print(f\"\\nConfidence distribution for positive cases:\")\n",
    "    print(f\"Mean confidence: {positive_cases['bilateral_confidence'].mean():.2f}\")\n",
    "    print(f\"Median confidence: {positive_cases['bilateral_confidence'].median():.2f}\")\n",
    "    print(f\"High confidence cases (竕･0.5): {(positive_cases['bilateral_confidence'] >= 0.5).sum():,}\")\n",
    "\n",
    "# Unique patients and admissions\n",
    "print(f\"\\nUnique subjects with bilateral opacities: {positive_cases['subject_id'].nunique():,}\")\n",
    "print(f\"Unique admissions with bilateral opacities: {positive_cases['hadm_id'].nunique():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Examples of Detected Bilateral Opacities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show examples of detected bilateral opacities\n",
    "print(\"=== EXAMPLES OF DETECTED BILATERAL OPACITIES ===\")\n",
    "\n",
    "# Get high-confidence examples\n",
    "high_conf_examples = results_df[\n",
    "    (results_df['has_bilateral_opacities']) & \n",
    "    (results_df['bilateral_confidence'] >= 0.4)\n",
    "].head(3)\n",
    "\n",
    "if len(high_conf_examples) > 0:\n",
    "    # Merge back with original text\n",
    "    examples_with_text = chest_reports_large.merge(\n",
    "        high_conf_examples[['note_id', 'bilateral_confidence']], \n",
    "        on='note_id'\n",
    "    )\n",
    "    \n",
    "    for i, (_, row) in enumerate(examples_with_text.iterrows()):\n",
    "        print(f\"\\n--- Example {i+1} (Confidence: {row['bilateral_confidence']:.2f}) ---\")\n",
    "        print(f\"Report ID: {row['note_id']}\")\n",
    "        print(f\"Subject ID: {row['subject_id']}\")\n",
    "        \n",
    "        # Show relevant sections\n",
    "        text = row['text']\n",
    "        if 'FINDINGS' in text.upper():\n",
    "            findings_start = text.upper().find('FINDINGS')\n",
    "            relevant_text = text[findings_start:findings_start+500]\n",
    "        else:\n",
    "            relevant_text = text[:500]\n",
    "        \n",
    "        print(\"Relevant text:\", relevant_text + \"...\")\n",
    "        \n",
    "        # Show what patterns were detected\n",
    "        bilateral_result = detector.detect_bilateral_opacities(text)\n",
    "        print(f\"Detected patterns: {len(bilateral_result['matched_patterns'])}\")\n",
    "        for pattern_info in bilateral_result['matched_patterns']:\n",
    "            print(f\"  - Found: {pattern_info['matches']}\")\n",
    "else:\n",
    "    print(\"No high-confidence examples found in this sample.\")\n",
    "    # Show any positive examples\n",
    "    any_positive = results_df[results_df['has_bilateral_opacities']].head(2)\n",
    "    if len(any_positive) > 0:\n",
    "        print(\"\\nShowing lower-confidence examples:\")\n",
    "        examples_with_text = chest_reports_large.merge(\n",
    "            any_positive[['note_id', 'bilateral_confidence']], \n",
    "            on='note_id'\n",
    "        )\n",
    "        \n",
    "        for i, (_, row) in enumerate(examples_with_text.iterrows()):\n",
    "            print(f\"\\n--- Example {i+1} (Confidence: {row['bilateral_confidence']:.2f}) ---\")\n",
    "            print(f\"Report ID: {row['note_id']}\")\n",
    "            print(\"Text preview:\", row['text'][:300] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Results for Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save detection results\n",
    "results_df.to_csv('../data/bilateral_opacity_detection_results.csv', index=False)\n",
    "print(f\"Results saved to ../data/bilateral_opacity_detection_results.csv\")\n",
    "print(f\"Shape: {results_df.shape}\")\n",
    "\n",
    "# Summary for next notebook\n",
    "print(\"\\n=== SUMMARY FOR NEXT STEPS ===\")\n",
    "print(f\"笨 Bilateral opacity detection implemented and tested\")\n",
    "print(f\"笨 Found {results_df['has_bilateral_opacities'].sum():,} potential ARDS cases\")\n",
    "print(f\"笨 {results_df['subject_id'].nunique():,} unique subjects in dataset\")\n",
    "print(f\"\")\n",
    "print(f\"沁ｯ Next steps:\")\n",
    "print(f\"   1. Extract ventilator parameters (P/F ratio, PEEP)\")\n",
    "print(f\"   2. Add BMI/obesity classification\")\n",
    "print(f\"   3. Define clinical outcomes\")\n",
    "print(f\"   4. Statistical analysis of obesity-plateau pressure interaction\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ards-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
